{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "#from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "f_3a4='backlog3a4-pcba_allocation.csv'\n",
    "f_supply='test_SCR+OH+Intransit_0924.xlsx'\n",
    "sheet_scr='scr'\n",
    "sheet_transit='in-transit'\n",
    "sheet_oh='OH & transit-time'\n",
    "\n",
    "ranking_col=['priority_rank', 'ossd_offset', 'fcd_offset','rev_non_rev_rank','C_UNSTAGED_QTY', 'SO_SS','PO_NUMBER']\n",
    "\n",
    "# backlog offset by transit pad will not consider ocean ship - assuming ocean is to cocver fcst demand but not backlog demand\n",
    "transit_time={'FOL':{'FOC':2,'other':7}, \n",
    "            'JPE':{'JPE':1,'other':7}\n",
    "           }\n",
    "\n",
    "pcba_site='FOL'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_supply_to_versionless_and_addup_supply(df,org_col='planningOrg',pn_col='TAN'):\n",
    "    \"\"\"\n",
    "    Change PN in supply or OH df into versionless. Add up the qty into the versionless PN.\n",
    "    :param df: the supply df or oh df\n",
    "    :param pn_col: name of the PN col. In Cm supply file it's PN, in Kinaxis file it's TAN.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    regex = re.compile(r'\\d{2,3}-\\d{4,7}')\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # convert to versionless and add temp col\n",
    "    df.loc[:,pn_col] = df[pn_col].map(lambda x: regex.search(x).group())\n",
    "    df.loc[:,'org_pn']=df[org_col] + '_' + df[pn_col]\n",
    "\n",
    "    # add up the duplicate PN (due to multiple versions)\n",
    "    df.sort_values(by=['org_pn'],inplace=True)\n",
    "    dup_pn = df[df.duplicated(['org_pn'])]['org_pn'].unique()\n",
    "    df_sum = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    df_sum.set_index([org_col,pn_col,'org_pn'], inplace=True)\n",
    "    df.set_index([org_col,pn_col,'org_pn'], inplace=True)\n",
    "        \n",
    "    for org_pn in dup_pn:\n",
    "        # print(df_supply[df_supply.PN==pn].sum(axis=1).sum())\n",
    "        df_sum.loc[(org_pn[:3],org_pn[4:],org_pn), :] = df.loc[(org_pn[:3],org_pn[4:],org_pn), :].sum(axis=0)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df.set_index('org_pn',inplace=True)\n",
    "    df.drop(dup_pn, axis=0, inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.set_index([org_col,pn_col,'org_pn'], inplace=True)\n",
    "    #print(df.columns)\n",
    "    #df.drop(['level_0','index'],axis=1,inplace=True)\n",
    "    df = pd.concat([df, df_sum])\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(['org_pn'],axis=1,inplace=True)\n",
    "    df.set_index([org_col,pn_col], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_date_with_transit_pad(x,y,transit_time,pcba_site):\n",
    "    \"\"\"\n",
    "    offset transit time to a given date column\n",
    "    \"\"\"\n",
    "    if x in transit_time[pcba_site].keys():\n",
    "        return y - pd.Timedelta(days=transit_time[pcba_site][x])\n",
    "    else:\n",
    "        return y - pd.Timedelta(days=transit_time[pcba_site]['other'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df_order_bom_from_flb_tan_col(df_3a4,pcba):\n",
    "    \"\"\"\n",
    "    Generate the BOM usage file from the FLB_TAN col\n",
    "    :param df_3a4:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    regex_pn = re.compile(r'\\d{2,3}-\\d{4,7}')\n",
    "    regex_usage = re.compile(r'\\([0-9.]+\\)')\n",
    "\n",
    "    df_flb_tan = df_3a4[df_3a4.FLB_TAN.notnull()][['PO_NUMBER','PRODUCT_ID','ORDERED_QUANTITY','FLB_TAN']].copy()\n",
    "    #df_flb_tan.drop_duplicates(['PRODUCT_ID'], keep='first', inplace=True)\n",
    "\n",
    "    po_list=[]\n",
    "    pn_list = []\n",
    "    usage_list = []\n",
    "    for row in df_flb_tan.itertuples(index=False):\n",
    "        po=row.PO_NUMBER\n",
    "        flb_tan = row.FLB_TAN\n",
    "        #order_qty = row.ORDERED_QUANTITY\n",
    "        flb_tan=flb_tan.split('|')\n",
    "        \n",
    "        for item in flb_tan:\n",
    "            try:\n",
    "                pn = regex_pn.search(item).group()\n",
    "                usage = regex_usage.search(item).group()\n",
    "                usage = float(usage[1:-1])\n",
    "                \n",
    "                if pn in pcba:\n",
    "                    po_list.append(po)\n",
    "                    pn_list.append(pn)\n",
    "                    usage_list.append(usage)\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "                #print(po_list)\n",
    "        \n",
    "    #print(po_list)\n",
    "    df_order_bom_from_flb = pd.DataFrame({'PO_NUMBER': po_list, 'BOM_PN': pn_list, 'BOM_PN_QTY': usage_list})\n",
    "\n",
    "    return df_order_bom_from_flb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_order_bom_to_3a4(df_3a4, df_order_bom):\n",
    "    \"\"\"\n",
    "    Add PN into 3a4 based on BOM\n",
    "    :param df_3a4:\n",
    "    :param df_bom:\n",
    "    :return: df_3a4, df_missing_bom_pid\n",
    "    \"\"\"\n",
    "    # add the BOM PN through merge method\n",
    "    df_3a4 = pd.merge(df_3a4, df_order_bom, left_on='PO_NUMBER', right_on='PO_NUMBER', how='left')\n",
    "\n",
    "    \"\"\"\n",
    "    # PID missing BOM data\n",
    "    missing_bom_pid = df_3a4[df_3a4.TAN.notnull() & df_3a4.PN.isnull()].PRODUCT_ID.unique()\n",
    "    df_missing_bom_pid = pd.DataFrame({'Missing BOM PID': missing_bom_pid})\n",
    "\n",
    "    # 对于BOM missing 的采用3a4中已有的TAN\n",
    "    df_3a4.loc[:, 'PN'] = np.where(df_3a4.TAN.notnull() & df_3a4.PN.isnull(),\n",
    "                                   df_3a4.TAN,\n",
    "                                   df_3a4.PN)\n",
    "    \"\"\"\n",
    "    # correct the quantity by multiplying BOM Qty\n",
    "    df_3a4.loc[:, 'C_UNSTAGED_QTY']=df_3a4.C_UNSTAGED_QTY * (df_3a4.BOM_PN_QTY/df_3a4.ORDERED_QUANTITY)\n",
    "    df_3a4.loc[:, 'ORDERED_QUANTITY'] = df_3a4.BOM_PN_QTY\n",
    "\n",
    "    # add indicator for distinct PO filtering\n",
    "    df_3a4.loc[:,'distinct_po_filter']=np.where(~df_3a4.duplicated('PO_NUMBER'),\n",
    "                                              'YES',\n",
    "                                                '')\n",
    "\n",
    "\n",
    "    return df_3a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def created_supply_dict_per_scr(df_scr):\n",
    "    \"\"\"\n",
    "    create supply dict based on scr\n",
    "    supply_dic_tan={'800-42373':[{'2/10':25},{'2/12':4},{'2/15':10},{'2/22':20},{'3/1':10},{'3/5':15}],\n",
    "               '800-42925':[{'2/12':4},{'2/13':3},{'2/15':12},{'2/23':25},{'3/1':8},{'3/6':10}]}\n",
    "    \"\"\"\n",
    "    supply_dic_tan={}\n",
    "    \n",
    "    \n",
    "    for tan in df_scr.index:\n",
    "        date_qty_list=[]\n",
    "        for date in df_scr.columns:\n",
    "            date_qty={date:df_scr.loc[tan,date]}\n",
    "            if not math.isnan(df_scr.loc[tan,date]): # 判断数值是否为空\n",
    "                if df_scr.loc[tan,date]>0: # 不取0值\n",
    "                    date_qty_list.append(date_qty)\n",
    "        supply_dic_tan[tan]=date_qty_list\n",
    "        \n",
    "    \"\"\" Below version spends much logner time to create the dict. use above instead with index simplified.\n",
    "    for org_tan in df_scr.index:\n",
    "        org=org_tan[0]\n",
    "        tan=org_tan[1]\n",
    "        date_qty_list=[]\n",
    "        for date in df_scr.columns:\n",
    "            date_qty={date:df_scr.loc[(org,tan),date]}\n",
    "            if not math.isnan(df_scr.loc[(org,tan),date]): # 判断数值是否为空\n",
    "                if df_scr.loc[(org,tan),date]>0: # 不取0值\n",
    "                    date_qty_list.append(date_qty)\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    return supply_dic_tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def created_oh_dict_per_df_oh(df_oh,pcba_site):\n",
    "    \"\"\"\n",
    "    create OH dict based on DF OH (excluding PCBA site and only consider OH>0 items)\n",
    "    supply_dic_tan={(FOC,'800-42373'):25,(FJZ,'800-42925'):100}\n",
    "    \"\"\"\n",
    "    df_oh=df_oh[(df_oh.OH>0)]\n",
    "    df_oh.reset_index(inplace=True)\n",
    "    oh_dic_tan={}\n",
    "    for row in df_oh[1:].itertuples(index=False):\n",
    "        org=row.planningOrg\n",
    "        tan=row.TAN\n",
    "        oh=row.OH\n",
    "        \n",
    "        if org!=pcba_site:\n",
    "            oh_dic_tan[(org,tan)]=oh\n",
    "    \n",
    "    return oh_dic_tan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blg_dict_per_sorted_3a4_and_selected_tan(df_3a4,tan):\n",
    "    \"\"\"\n",
    "    create backlog dict for selected tan list from the sorted 3a4 df (considered order prioity and rank)\n",
    "    \"\"\"\n",
    "    blg_dic_tan={}\n",
    "    for pn in tan:\n",
    "        dfm=df_3a4[df_3a4.BOM_PN==pn]\n",
    "        org_qty_po=[]\n",
    "        for org,qty,po in zip(dfm.ORGANIZATION_CODE,dfm.BOM_PN_QTY,dfm.PO_NUMBER):\n",
    "            if qty>0:\n",
    "                org_qty_po.append({org:(qty,po)})\n",
    "\n",
    "        blg_dic_tan[pn]=org_qty_po\n",
    "    \n",
    "    return blg_dic_tan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_supply_per_supply_and_blg_dic(supply_dic_tan,blg_dic_tan):\n",
    "    \"\"\"\n",
    "    allocate supply based on supply dict and backlog dict\n",
    "    supply dict is aranged in date order; backlog dict is aranged based on priority to fulfill\n",
    "    \n",
    "    examples: \n",
    "        blg_dic_tan={'800-42373-01': [{'FJZ': (5, '110077267-1')},{'FJZ': (23, '110011089-4')},...]}\n",
    "        supply_dic_tan={'800-42373-01':[{'2/10':25},{'2/12':4},{'2/15':10},{'2/22':20},{'3/1':10},{'3/5':15}],\n",
    "                             '800-42925-01':[{'2/12':4},{'2/13':3},{'2/15':12},{'2/23':25},{'3/1':8},{'3/6':10}]}\n",
    "    \"\"\"\n",
    "    supply_dic_tan_allocated={}\n",
    "    \n",
    "    for tan in supply_dic_tan.keys():\n",
    "        supply_list_tan=supply_dic_tan[tan]  #每一个tan对应的supply list\n",
    "\n",
    "        if tan in blg_dic_tan.keys(): #\n",
    "            blg_list_tan=blg_dic_tan[tan]\n",
    "\n",
    "            # 对supply list中每一个值进行分配给一个或多个订单\n",
    "            for date_qty in supply_list_tan:\n",
    "                #print(date_qty)\n",
    "                supply_date=list(date_qty.keys())[0]\n",
    "                supply_qty=list(date_qty.values())[0]\n",
    "                allocation=[] #每一个supply的分配结果\n",
    "\n",
    "                allocated_po=[] #已经分配给对应数量的po\n",
    "                # 对每一个po进行数量分配\n",
    "                for po in blg_list_tan:\n",
    "                    #print(po)\n",
    "                    po_qty=list(po.values())[0][0]\n",
    "                    po_org=list(po.keys())[0]\n",
    "                    po_number=list(po.values())[0][1]\n",
    "                    \n",
    "                    #print(po_qty)\n",
    "                    #print(supply_qty)\n",
    "                    if po_qty<supply_qty: #po数量小于supply数量：po被全额满足；supply数量被减掉；已分配的po被记录 （后面跳转到下一个po）\n",
    "                        allocation.append((po_org,po_qty))\n",
    "                        supply_qty=supply_qty-po_qty\n",
    "                        allocated_po.append(po)\n",
    "                    elif po_qty==supply_qty: #po数量等于supply数量：po被全额满足；已分配的po被记录；跳出本次po循环(进到下一个supply循环)\n",
    "                        allocation.append((po_org,po_qty))\n",
    "                        allocated_po.append(po)\n",
    "                        break\n",
    "                    else: #po数量大于supply数量：po被部分（=supply qty）满足；po数量被改小；跳出本次po循环(进到下一个supply循环)\n",
    "                        allocation.append((po_org,supply_qty))\n",
    "                        new_po_qty=po_qty-supply_qty\n",
    "                        ind=blg_list_tan.index(po)\n",
    "                        blg_list_tan[ind]={po_org:(new_po_qty,po_number)}\n",
    "                        break\n",
    "\n",
    "                #print(allocated_po)\n",
    "                # 把已经被分配的po从列表中删除\n",
    "                for po in allocated_po:\n",
    "                    #print(po)\n",
    "                    blg_list_tan.remove(po)   # double check this one of removing PO whether correct or not\n",
    "                    blg_dic_tan[tan]=blg_list_tan\n",
    "\n",
    "\n",
    "                # 把supply列表中对应的supply改变成分配的结果\n",
    "                ind=supply_list_tan.index(date_qty)\n",
    "                supply_date=list(date_qty.keys())[0]\n",
    "                supply_qty=list(date_qty.values())[0]\n",
    "                supply_list_tan[ind]={supply_date:(supply_qty,allocation)}\n",
    "\n",
    "        #生成新的allocated supply dict\n",
    "        supply_dic_tan_allocated[tan]=supply_list_tan\n",
    "    \n",
    "    return supply_dic_tan_allocated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_allocation_for_each_date(a,date_supply_agg):\n",
    "    \"\"\"\n",
    "    # 根据日期及org汇合每个日期dict下的数量 \n",
    "    a={'2/12': (4, [('FCZ', 1), ('FJZ', 1), ('FJZ', 1), ('FJZ', 1)])}\n",
    "    date_supply_agg={}\n",
    "    此函数在aggregate_supply_dic_tan_allocated中引用\n",
    "    \"\"\"\n",
    "    date=list(a.keys())[0]\n",
    "    supply=list(a.values())[0][1]  \n",
    "    supply_total_qty=list(a.values())[0][0]  \n",
    "    \n",
    "    orgs=[]\n",
    "    for org_supply in supply:\n",
    "        if org_supply[0] not in orgs:\n",
    "            orgs.append(org_supply[0])\n",
    "    \n",
    "    allocation_agg=[]\n",
    "    for org in orgs:\n",
    "        qty=0\n",
    "        for org_supply in supply:\n",
    "            if org_supply[0]==org:\n",
    "                qty+=org_supply[1]\n",
    "        \n",
    "        allocation_agg.append((org,qty))\n",
    "    \n",
    "    date_supply_agg={}\n",
    "    date_supply_agg[date]=(supply_total_qty,allocation_agg)\n",
    "    \n",
    "    return date_supply_agg\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_supply_dic_tan_allocated(supply_dic_tan_allocated):\n",
    "    \"\"\"\n",
    "    针对每一个tan按照每一个日期将分配的数量按照org汇总(引用函数aggregate_allocation_for_each_date)\n",
    "    \"\"\"\n",
    "    supply_dic_tan_allocated_agg={}\n",
    "    for tan,tan_supply in supply_dic_tan_allocated.items():\n",
    "        tan_supply_list=[]\n",
    "        for date_supply in tan_supply:\n",
    "            date_supply_agg={}\n",
    "            date_supply_agg=aggregate_allocation_for_each_date(date_supply,date_supply_agg)\n",
    "            tan_supply_list.append(date_supply_agg)\n",
    "\n",
    "        supply_dic_tan_allocated_agg[tan]=tan_supply_list\n",
    "    \n",
    "    return supply_dic_tan_allocated_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fulfill_backlog_by_oh(oh_dic_tan, blg_dic_tan):\n",
    "    \"\"\"\n",
    "    Fulfill the backlog per DF site based on the DF site OH; deduct the backlog qty accordingly.\n",
    "    examples:\n",
    "        blg_dic_tan={'800-42373': [{'FJZ': (5, ('110077267-1','2020-4-1'))},{'FJZ': (23, ('110011089-4','2020-4-4'))},...]}\n",
    "        oh_dic_tan={('FJZ',800-42373'):25,('FCZ',800-42925'):10}\n",
    "    return: blg_dic_tan\n",
    "    \"\"\"\n",
    "    for org_tan,qty in oh_dic_tan.items():\n",
    "        oh_org=org_tan[0]\n",
    "        oh_tan=org_tan[1]\n",
    "        oh_qty=qty\n",
    "        \n",
    "        if oh_tan in blg_dic_tan.keys():  # blg_dic_tan只包含scr中的tan，oh_tan可能不在其中，如不在，不予考虑\n",
    "            blg_dic_tan_list=blg_dic_tan[oh_tan] #对应tan下的内容\n",
    "            blg_dic_tan_list_copy=blg_dic_tan_list.copy()\n",
    "            \n",
    "            # 按顺序对每一个po进行数量分配\n",
    "            for org_po in blg_dic_tan_list:\n",
    "                po_org=list(org_po.keys())[0]\n",
    "                po_qty = list(org_po.values())[0][0]\n",
    "                po_number = list(org_po.values())[0][1]\n",
    "                \n",
    "                if po_org==oh_org:\n",
    "                    po_qty_new=po_qty-oh_qty\n",
    "                    oh_qty_new=oh_qty - po_qty\n",
    "                    if po_qty_new<=0: #po已被oh cover完，移除po\n",
    "                        blg_dic_tan_list_copy.remove(org_po)\n",
    "                        oh_qty=oh_qty_new\n",
    "                    else: # oh consumed\n",
    "                        index=blg_dic_tan_list_copy.index(org_po)\n",
    "                        blg_dic_tan_list_copy[index]={po_org:(po_qty_new,po_number)}\n",
    "                    \n",
    "                        break\n",
    "            # 更新blg_dic_tan\n",
    "            blg_dic_tan[oh_tan]=blg_dic_tan_list_copy\n",
    "                \n",
    "    return blg_dic_tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_allocation_to_scr(df_scr,df_3a4,supply_dic_tan_allocated_agg,pcba_site):\n",
    "    \"\"\"\n",
    "    Add up the allocation results to scr and create the final output file\n",
    "    \"\"\"\n",
    "    pcba_site_temp='A-' + pcba_site\n",
    "    df_scr.loc[:,'ORG']=pcba_site_temp\n",
    "    df_scr.reset_index(inplace=True)\n",
    "    df_scr.set_index(['TAN','ORG'],inplace=True)\n",
    "    \n",
    "    # Add in orgs based on 3a4\n",
    "    df_3a4_p=df_3a4.pivot_table(index=['BOM_PN','ORGANIZATION_CODE'],values='PO_NUMBER',aggfunc=len)\n",
    "    df_3a4_p.reset_index(inplace=True)\n",
    "    \n",
    "    for row in df_3a4_p.itertuples():\n",
    "        tan=row.BOM_PN\n",
    "        org=row.ORGANIZATION_CODE\n",
    "        \n",
    "        if tan in df_scr.index:\n",
    "            df_scr.loc[(tan,org),'count']=row.PO_NUMBER\n",
    "    df_scr.drop('count',axis=1,inplace=True)\n",
    "    \n",
    "    # add in allocated qty\n",
    "    for tan in supply_dic_tan_allocated_agg.keys():\n",
    "        for date_supply in supply_dic_tan_allocated_agg[tan]:\n",
    "            date=list(date_supply.keys())[0]\n",
    "            org_qty=list(date_supply.values())[0][1]\n",
    "            for x in org_qty:\n",
    "                df_scr.loc[(tan,x[0]),date]=x[1]\n",
    "\n",
    "    df_scr.reset_index(inplace=True)\n",
    "    df_scr.sort_values(by=['TAN','ORG'],ascending=True,inplace=True)\n",
    "    df_scr.loc[:,'ORG']=df_scr.ORG.map(lambda x: pcba_site if 'A-' in x else x)\n",
    "    df_scr.set_index(['TAN','ORG'],inplace=True)\n",
    "    \n",
    "    return df_scr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bu_from_scr(df_scr):\n",
    "    \"\"\"\n",
    "    Versionless the PN and extract the BU info from original scr before pivoting\n",
    "    \"\"\"\n",
    "    regex_pn = re.compile(r'\\d{2,3}-\\d{4,7}')\n",
    "    \n",
    "    tan_bu={}\n",
    "    for row in df_scr.itertuples(index=False):\n",
    "        tan = regex_pn.search(row.TAN).group()\n",
    "        tan_bu[tan]=row.BU\n",
    "    \n",
    "    return tan_bu\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_final_allocated_output(df_scr,tan_bu,df_3a4,df_oh,pcba_site):\n",
    "    \"\"\"\n",
    "    Add back the BU, backlog,oh, intransit info into the final SCR with allocation result; and add the related columns based on calculations.\n",
    "    \"\"\"\n",
    "    df_scr.reset_index(inplace=True)\n",
    "    \n",
    "    # add BU info\n",
    "    df_scr.loc[:,'BU']=df_scr.TAN.map(lambda x: tan_bu[x])\n",
    "    \n",
    "    # add backlog qty\n",
    "    df_3a4_p=df_3a4.pivot_table(index=['ORGANIZATION_CODE','BOM_PN'],values='BOM_PN_QTY',aggfunc=sum)\n",
    "    df_3a4_p.columns=['Backlog']\n",
    "    df_3a4_p.reset_index(inplace=True)\n",
    "    df_scr=pd.merge(df_scr,df_3a4_p,left_on=['ORG','TAN'],right_on=['ORGANIZATION_CODE','BOM_PN'],how='left')\n",
    "    \n",
    "    # add df OH\n",
    "    df_oh.columns=['OH']\n",
    "    df_oh.reset_index(inplace=True)\n",
    "    df_oh=df_oh[df_oh.planningOrg!=pcba_site]\n",
    "    df_scr=pd.merge(df_scr,df_oh,left_on=['ORG','TAN'],right_on=['planningOrg','TAN'],how='left')\n",
    "    \n",
    "    # drop the unneeded columns introduced by merge\n",
    "    df_scr.drop(['ORGANIZATION_CODE','BOM_PN','planningOrg'],axis=1,inplace=True)\n",
    "    #df_scr.rename(columns={'TAN_x':'TAN'},inplace=True)\n",
    "    \n",
    "    # ADD THE gap col and recovery date\n",
    "    df_scr.loc[:,'Gap_before']=np.where(df_scr.ORG!=pcba_site,\n",
    "                                         np.where(df_scr.OH.isnull(),\n",
    "                                                 0 - df_scr.Backlog,\n",
    "                                                 df_scr.OH - df_scr.Backlog),\n",
    "                                        None)\n",
    "    df_scr.loc[:,'Allocation']=np.where(df_scr.ORG!=pcba_site,\n",
    "                                         df_scr.iloc[:,3:-4].sum(axis=1),\n",
    "                                        None)\n",
    "                                                     \n",
    "    df_scr.loc[:,'Gap_after']=np.where(df_scr.ORG!=pcba_site,\n",
    "                                         df_scr.Gap_before+df_scr.Allocation,\n",
    "                                        None)\n",
    "    \n",
    "    df_scr.loc[:,'Recovery']=np.where(df_scr.Gap_before>=0,\n",
    "                                           \"No gap\",\n",
    "                                          np.where(df_scr.Gap_after<0,\n",
    "                                                  'No recovery',\n",
    "                                                  'TBD'))\n",
    "    \n",
    "    # update with the correct recovery date for TBD\n",
    "    df_scr.set_index(['TAN','ORG','BU','Backlog','OH','Gap_before','Allocation','Gap_after','Recovery'],inplace=True)\n",
    "    df_scr.reset_index(inplace=True)\n",
    "    dfx=df_scr[(df_scr.Recovery=='TBD')&(df_scr.ORG!=pcba_site)]\n",
    "    dfx.set_index(['TAN','ORG'],inplace=True)\n",
    "    df_scr.set_index(['TAN','ORG'],inplace=True)\n",
    "    \n",
    "    for ind in dfx.index:\n",
    "        dfy=dfx.loc[ind,:]\n",
    "        dfy=dfy[dfy.notnull()]\n",
    "            \n",
    "        last_allocation_date=dfy.index[-1]\n",
    "        df_scr.loc[ind,'Recovery']=last_allocation_date\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    df_scr.reset_index(inplace=True)\n",
    "    df_scr.set_index(['TAN','ORG','BU','Backlog','OH','Gap_before','Allocation','Gap_after','Recovery'],inplace=True)\n",
    "    \n",
    "    return df_scr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_ranking_overall_new(df_3a4,ranking_col, order_col='SO_SS', new_col='ss_overall_rank'):\n",
    "    \"\"\"\n",
    "    根据priority_cat,OSSD,FCD, REVENUE_NON_REVENUE,C_UNSTAGED_QTY,按照ranking_col的顺序对SS进行排序。最后放MFG_HOLD订单.\n",
    "    :param df_3a4:\n",
    "    :param ranking_col:e.g. ['priority_rank', 'ORIGINAL_FCD_NBD_DATE', 'CURRENT_FCD_NBD_DATE','rev_non_rev_rank',\n",
    "                        'C_UNSTAGED_QTY', 'SO_SS','PO_NUMBER']\n",
    "    :param order_col:'SO_SS'\n",
    "    :param new_col:'ss_overall_rank'\n",
    "    :return: df_3a4\n",
    "    \"\"\"\n",
    "    # Below create a rev_rank for reference -  currently not used in overall ranking\n",
    "    ### change non-rev orders unstaged $ to 0\n",
    "    df_3a4.loc[:,'C_UNSTAGED_DOLLARS']=np.where(df_3a4.REVENUE_NON_REVENUE == 'NO',\n",
    "                                                0,\n",
    "                                                df_3a4.C_UNSTAGED_DOLLARS)\n",
    "\n",
    "    #### 生成ss_unstg_rev并据此排序\n",
    "    # 计算ss_unstg_rev\n",
    "    ss_unstg_rev = {}\n",
    "    df_rev = df_3a4.pivot_table(index='SO_SS', values='C_UNSTAGED_DOLLARS', aggfunc=sum)\n",
    "    for ss, rev in zip(df_rev.index, df_rev.values):\n",
    "        ss_unstg_rev[ss] = rev[0]\n",
    "    df_3a4.loc[:, 'ss_unstg_rev'] = df_3a4.SO_SS.map(lambda x: ss_unstg_rev[x])\n",
    "\n",
    "    \"\"\"\n",
    "    # 计算po_rev_unit - non revenue change to 0\n",
    "    df_3a4.loc[:, 'po_rev_unit'] = np.where(df_3a4.REVENUE_NON_REVENUE == 'YES',\n",
    "                                            df_3a4.SOL_REVENUE / df_3a4.ORDERED_QUANTITY,\n",
    "                                            0)\n",
    "\n",
    "    # 计算ss_rev_unit: 通过po_rev_unit汇总\n",
    "    ss_rev_unit = {}\n",
    "    dfx_rev = df_3a4.pivot_table(index='SO_SS', values='po_rev_unit', aggfunc=sum)\n",
    "    for ss, rev in zip(dfx_rev.index, dfx_rev.values):\n",
    "        ss_rev_unit[ss] = rev[0]\n",
    "    df_3a4.loc[:, 'ss_rev_unit'] = df_3a4.SO_SS.map(lambda x: int(ss_rev_unit[x]))\n",
    "    \"\"\"\n",
    "\n",
    "    # create rank#\n",
    "    rank = {}\n",
    "    order_list = df_3a4.sort_values(by='ss_unstg_rev', ascending=False).SO_SS.unique()\n",
    "    for order, rk in zip(order_list, range(1, len(order_list) + 1)):\n",
    "        rank[order] = rk\n",
    "    df_3a4.loc[:, 'ss_rev_rank'] = df_3a4.SO_SS.map(lambda x: rank[x])\n",
    "\n",
    "    # below creates overall ranking col\n",
    "    ### Step1: 重新定义priority order及排序\n",
    "    df_3a4.loc[:, 'priority_cat'] = np.where(df_3a4.SECONDARY_PRIORITY.isin(['PR1', 'PR2', 'PR3']),\n",
    "                                             df_3a4.SECONDARY_PRIORITY,\n",
    "                                             np.where(df_3a4.FINAL_ACTION_SUMMARY == 'TOP 100',\n",
    "                                                      'TOP 100',\n",
    "                                                      np.where(\n",
    "                                                          df_3a4.FINAL_ACTION_SUMMARY == 'LEVEL 4 ESCALATION PRESENT',\n",
    "                                                          'L4',\n",
    "                                                          np.where(df_3a4.BUP_RANK.notnull(),\n",
    "                                                                   'BUP',\n",
    "                                                                   None)\n",
    "                                                          )\n",
    "                                                      )\n",
    "                                             )\n",
    "    #### Update below DO/DX orders to PR1 due to current PR1/2/3 not updated when order change to DPAS from others\n",
    "    df_3a4.loc[:, 'priority_cat']=np.where((df_3a4.DPAS_RATING.isin(['DO','DX','TAA-DO','TAA-DX']))&(df_3a4.priority_cat.isnull()),\n",
    "                                           'PR1',\n",
    "                                           df_3a4.priority_cat)\n",
    "    #### Give them a rank\n",
    "    df_3a4.loc[:, 'priority_rank'] = np.where(df_3a4.priority_cat=='PR1',\n",
    "                                            1,\n",
    "                                            np.where(df_3a4.priority_cat =='PR2',\n",
    "                                                     2,\n",
    "                                                     np.where(df_3a4.priority_cat =='PR3',\n",
    "                                                              3,\n",
    "                                                              np.where(df_3a4.priority_cat == 'TOP 100',\n",
    "                                                                        4,\n",
    "                                                                        np.where(df_3a4.priority_cat == 'L4',\n",
    "                                                                                5,\n",
    "                                                                                np.where(df_3a4.priority_cat=='BUP',\n",
    "                                                                                         6,\n",
    "                                                                                         None)\n",
    "                                                                                )\n",
    "                                                                        )\n",
    "                                                                )\n",
    "                                                     )\n",
    "                                              )\n",
    "\n",
    "    ##### Step2: Give revenue/non-revenue a rank\n",
    "    df_3a4.loc[:,'rev_non_rev_rank']=np.where(df_3a4.REVENUE_NON_REVENUE=='YES', 0, 1)\n",
    "\n",
    "    ##### Step3: sort the SS per ranking columns and Put MFG hold orders at the back\n",
    "    df_3a4.sort_values(by=ranking_col, ascending=True, inplace=True)\n",
    "    # Put MFG hold orders at the back\n",
    "    df_hold=df_3a4[df_3a4.MFG_HOLD=='Y'].copy()\n",
    "    df_3a4=df_3a4[df_3a4.MFG_HOLD!='Y'].copy()\n",
    "    df_3a4=pd.concat([df_3a4,df_hold],sort=False)\n",
    "\n",
    "    ##### Step3: create rank# and put in 3a4\n",
    "    rank = {}\n",
    "    order_list = df_3a4[order_col].unique()\n",
    "    for order, rk in zip(order_list, range(1, len(order_list) + 1)):\n",
    "        rank[order] = rk\n",
    "    df_3a4.loc[:, new_col] = df_3a4[order_col].map(lambda x: rank[x])\n",
    "\n",
    "    return df_3a4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read 3a4, OH, Intransit, scr\n",
    "- Create Oh dict\n",
    "- Create intransit dict - how to deal with ETA TBD\n",
    "- Process 3a4\n",
    "- 3A4 consume DF OH by site\n",
    "- 3A4 consume intransit - how to deal with ETA TBD\n",
    "- Rank 3A4\n",
    "- Create scr dict\n",
    "- Allocate scr to 3a4\n",
    "- Summarize allocation result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 3a4\n",
    "df_3a4=pd.read_csv(f_3a4, encoding='ISO-8859-1',parse_dates=['CURRENT_FCD_NBD_DATE',  'ORIGINAL_FCD_NBD_DATE'],low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read scr\n",
    "df_scr=pd.read_excel(f_supply,sheet_name=sheet_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read oh this includes PCBA SM, will be removed when creating DF OH dict\n",
    "df_oh=pd.read_excel(f_supply,sheet_name=sheet_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in-transit\n",
    "df_transit=pd.read_excel(f_supply,sheet_name=sheet_transit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot df_oh\n",
    "df_oh=df_oh.pivot_table(index=['planningOrg','TAN'],values='OH',aggfunc=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versionless df_oh\n",
    "df_oh=change_supply_to_versionless_and_addup_supply(df_oh,pn_col='TAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成OH dict；\n",
    "oh_dic_tan=created_oh_dict_per_df_oh(df_oh,pcba_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract BU info for TAN from SCR\n",
    "tan_bu=extract_bu_from_scr(df_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot df_scr 并处理日期格式\n",
    "df_scr=df_scr.pivot_table(index=['planningOrg','TAN'],columns='SCRDate',values='SCRQuantity',aggfunc=sum)\n",
    "df_scr.columns=df_scr.columns.map(lambda x: x.date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versionless df_scr\n",
    "df_scr=change_supply_to_versionless_and_addup_supply(df_scr,pn_col='TAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the index will make it much faster to get the dict\n",
    "df_scr.reset_index(inplace=True)\n",
    "df_scr.drop('planningOrg',axis=1,inplace=True)\n",
    "df_scr.set_index('TAN',inplace=True)\n",
    "supply_dic_tan=created_supply_dict_per_scr(df_scr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset 3A4 OSSD and FCD by transit time\n",
    "df_3a4.loc[:,'fcd_offset']=df_3a4.apply(lambda x: update_date_with_transit_pad(x.ORGANIZATION_CODE, x.CURRENT_FCD_NBD_DATE,transit_time,pcba_site),axis=1)\n",
    "df_3a4.loc[:,'ossd_offset']=df_3a4.apply(lambda x: update_date_with_transit_pad(x.ORGANIZATION_CODE, x.ORIGINAL_FCD_NBD_DATE,transit_time,pcba_site),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the orders\n",
    "df_3a4=ss_ranking_overall_new(df_3a4,ranking_col, order_col='SO_SS', new_col='ss_overall_rank')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (do below after ranking) Process 3a4 BOM base on FLB_TAN col\n",
    "df_bom = generate_df_order_bom_from_flb_tan_col(df_3a4,supply_dic_tan.keys())\n",
    "df_3a4 = update_order_bom_to_3a4(df_3a4, df_bom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create backlog dict for Tan exists in SCR\n",
    "blg_dic_tan=create_blg_dict_per_sorted_3a4_and_selected_tan(df_3a4,supply_dic_tan.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oh to fulfill backlog per site. update blg_dic_tan accordingly\n",
    "blg_dic_tan=fulfill_backlog_by_oh(oh_dic_tan, blg_dic_tan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 按照org将in-transit分配给自己的订单（TBD: consider ETA or not - if new supply is considered to be availabe later than any intransit, then no need consider ETA but just total qty）\n",
    "# - 更新blg_dic_tan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate SCR and 生成allocated supply dict\n",
    "supply_dic_tan_allocated=allocate_supply_per_supply_and_blg_dic(supply_dic_tan,blg_dic_tan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成聚合的allocated supply dict\n",
    "supply_dic_tan_allocated_agg=aggregate_supply_dic_tan_allocated(supply_dic_tan_allocated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在df_scr中加入allocation结果\n",
    "df_scr=add_allocation_to_scr(df_scr,df_3a4,supply_dic_tan_allocated_agg,pcba_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  BU  Backlog     OH  Gap_before  Allocation  Gap_after  \\\n",
      "TAN       ORG                                                             \n",
      "68-100463 FJZ   UABU      1.0    NaN        -1.0         1.0        0.0   \n",
      "          SHK   UABU    247.0  163.0       -84.0        84.0        0.0   \n",
      "          SJZ   UABU    657.0    NaN      -657.0       657.0        0.0   \n",
      "68-100465 SJZ   UABU     70.0    NaN       -70.0        70.0        0.0   \n",
      "68-100466 SHK   UABU    231.0   46.0      -185.0       185.0        0.0   \n",
      "...              ...      ...    ...         ...         ...        ...   \n",
      "800-48419 FGU  SRGBU      4.0    NaN        -4.0         4.0        0.0   \n",
      "          FOC  SRGBU      7.0    5.0        -2.0         2.0        0.0   \n",
      "800-48768 FOC  INSBU     29.0   17.0       -12.0        12.0        0.0   \n",
      "800-48960 FTX  CSPBU     29.0    0.0       -29.0        29.0        0.0   \n",
      "800-49119 FOC  INSBU      8.0    3.0        -5.0         5.0        0.0   \n",
      "\n",
      "              Recovery 2018-07-15 2019-03-24 2019-07-10  ... 2021-02-01  \\\n",
      "TAN       ORG                                            ...              \n",
      "68-100463 FJZ      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "          SHK      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "          SJZ      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "68-100465 SJZ      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "68-100466 SHK      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "...                ...        ...        ...        ...  ...        ...   \n",
      "800-48419 FGU      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "          FOC      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "800-48768 FOC      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "800-48960 FTX      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "800-49119 FOC      TBD        NaN        NaN        NaN  ...        NaN   \n",
      "\n",
      "              2021-02-08 2021-02-15 2021-02-22 2021-02-24 2021-03-01  \\\n",
      "TAN       ORG                                                          \n",
      "68-100463 FJZ        NaN        NaN        NaN        NaN        NaN   \n",
      "          SHK        NaN        NaN        NaN        NaN        NaN   \n",
      "          SJZ        NaN        NaN        NaN        NaN        NaN   \n",
      "68-100465 SJZ        NaN        NaN        NaN        NaN        NaN   \n",
      "68-100466 SHK        NaN        NaN        NaN        NaN        NaN   \n",
      "...                  ...        ...        ...        ...        ...   \n",
      "800-48419 FGU        NaN        NaN        NaN        NaN        NaN   \n",
      "          FOC        NaN        NaN        NaN        NaN        NaN   \n",
      "800-48768 FOC        NaN        NaN        NaN        NaN        NaN   \n",
      "800-48960 FTX        NaN        NaN        NaN        NaN        NaN   \n",
      "800-49119 FOC        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "              2021-03-08 2021-03-15 2021-07-13 2023-01-30  \n",
      "TAN       ORG                                              \n",
      "68-100463 FJZ        NaN        NaN        NaN        NaN  \n",
      "          SHK        NaN        NaN        NaN        NaN  \n",
      "          SJZ        NaN        NaN        NaN        NaN  \n",
      "68-100465 SJZ        NaN        NaN        NaN        NaN  \n",
      "68-100466 SHK        NaN        NaN        NaN        NaN  \n",
      "...                  ...        ...        ...        ...  \n",
      "800-48419 FGU        NaN        NaN        NaN        NaN  \n",
      "          FOC        NaN        NaN        NaN        NaN  \n",
      "800-48768 FOC        NaN        NaN        NaN        NaN  \n",
      "800-48960 FTX        NaN        NaN        NaN        NaN  \n",
      "800-49119 FOC        NaN        NaN        NaN        NaN  \n",
      "\n",
      "[1152 rows x 70 columns]\n",
      "MultiIndex([('68-100463', 'FJZ'),\n",
      "            ('68-100463', 'SHK'),\n",
      "            ('68-100463', 'SJZ'),\n",
      "            ('68-100465', 'SJZ'),\n",
      "            ('68-100466', 'SHK'),\n",
      "            ('68-100466', 'SJZ'),\n",
      "            ('68-100467', 'FJZ'),\n",
      "            ('68-100467', 'FVE'),\n",
      "            ('68-100467', 'SJZ'),\n",
      "            ('68-100468', 'SHK'),\n",
      "            ...\n",
      "            ('800-48013', 'FVE'),\n",
      "            ('800-48013', 'SJZ'),\n",
      "            ('800-48024', 'FOC'),\n",
      "            ('800-48088', 'FOC'),\n",
      "            ('800-48129', 'FOC'),\n",
      "            ('800-48419', 'FGU'),\n",
      "            ('800-48419', 'FOC'),\n",
      "            ('800-48768', 'FOC'),\n",
      "            ('800-48960', 'FTX'),\n",
      "            ('800-49119', 'FOC')],\n",
      "           names=['TAN', 'ORG'], length=1152)\n",
      "('68-100463', 'FJZ')\n",
      "BU            UABU\n",
      "Backlog          1\n",
      "OH             NaN\n",
      "Gap_before      -1\n",
      "Allocation       1\n",
      "              ... \n",
      "2021-03-01     NaN\n",
      "2021-03-08     NaN\n",
      "2021-03-15     NaN\n",
      "2021-07-13     NaN\n",
      "2023-01-30     NaN\n",
      "Name: (68-100463, FJZ), Length: 70, dtype: object\n",
      "BU            UABU\n",
      "Backlog          1\n",
      "Gap_before      -1\n",
      "Allocation       1\n",
      "Gap_after        0\n",
      "Recovery       TBD\n",
      "2020-09-23       1\n",
      "Name: (68-100463, FJZ), dtype: object\n"
     ]
    }
   ],
   "source": [
    "#把以下信息加回scr: BU, backlog, OH, intransit; 并做相应的计算处理\n",
    "df_scr=process_final_allocated_output(df_scr,tan_bu,df_3a4,df_oh,pcba_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scr.to_excel('scr with allocation.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAN</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68-100463</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68-100465</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68-100466</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68-100467</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68-100468</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800-49638</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800-49639</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800-49759</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800-50192</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800-50194</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>983 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ORG\n",
       "TAN           \n",
       "68-100463    5\n",
       "68-100465    4\n",
       "68-100466    4\n",
       "68-100467    5\n",
       "68-100468    4\n",
       "...        ...\n",
       "800-49638    2\n",
       "800-49639    2\n",
       "800-49759    3\n",
       "800-50192    2\n",
       "800-50194    2\n",
       "\n",
       "[983 rows x 1 columns]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scr.reset_index(inplace=True)\n",
    "summary=df_scr.pivot_table(index='TAN',values='ORG',aggfunc=len)\n",
    "summary[summary.ORG>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
